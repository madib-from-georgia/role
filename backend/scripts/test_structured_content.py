#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
"""

import sys
import asyncio
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ backend –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
backend_path = Path(__file__).parent.parent
sys.path.append(str(backend_path))

from sqlalchemy.orm import Session
from app.database.connection import get_db
from app.database.crud import text as text_crud
from app.services.nlp_processor import get_nlp_processor
from app.parsers import fb2_parser, txt_parser
from loguru import logger

async def test_structured_content_parsing():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    
    logger.info("=== –¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ ===")
    
    # –¢–µ—Å—Ç–æ–≤—ã–π FB2 —Ñ–∞–π–ª
    fb2_file = Path(__file__).parent.parent.parent / "books" / "fb2" / "15) 1896 - –î—è–¥—è –í–∞–Ω—è.fb2"
    
    if not fb2_file.exists():
        logger.error(f"–¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {fb2_file}")
        return
    
    logger.info(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞: {fb2_file}")
    
    try:
        # –ü–∞—Ä—Å–∏–Ω–≥ –≤ –Ω–æ–≤—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        logger.info("üîÑ –ü–∞—Ä—Å–∏–Ω–≥ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç...")
        structured_content = fb2_parser.parse_to_structured_content(str(fb2_file))
        
        logger.success(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        logger.info(f"   –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(structured_content.elements)}")
        logger.info(f"   –î–∏–∞–ª–æ–≥–æ–≤: {len(structured_content.get_dialogues())}")
        logger.info(f"   –°–ø–∏—Å–∫–æ–≤ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(structured_content.get_character_lists())}")
        logger.info(f"   –ì–æ–≤–æ—Ä—è—â–∏—Ö: {len(structured_content.get_speakers())}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≥–æ–≤–æ—Ä—è—â–∏—Ö
        speakers = structured_content.get_speakers()
        if speakers:
            logger.info(f"üé≠ –ù–∞–π–¥–µ–Ω—ã –≥–æ–≤–æ—Ä—è—â–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏:")
            for speaker in speakers[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã—Ö 10
                dialogue_count = structured_content.get_dialogue_count_by_speaker().get(speaker, 0)
                logger.info(f"   ‚Ä¢ {speaker} ({dialogue_count} —Ä–µ–ø–ª–∏–∫)")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏–∑ —Å–ø–∏—Å–∫–æ–≤
        char_lists = structured_content.get_character_lists()
        if char_lists:
            logger.info(f"üìã –ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –∏–∑ —Å–ø–∏—Å–∫–æ–≤:")
            for char_list in char_lists:
                logger.info(f"   –°–µ–∫—Ü–∏—è: {char_list.content}")
                for char in char_list.characters[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã—Ö 5
                    desc = char.get('description', '')
                    logger.info(f"     ‚Ä¢ {char['name']}{' - ' + desc if desc else ''}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–∏–∞–ª–æ–≥–æ–≤
        dialogues = structured_content.get_dialogues()
        if dialogues:
            logger.info(f"üí¨ –ü—Ä–∏–º–µ—Ä—ã –¥–∏–∞–ª–æ–≥–æ–≤:")
            for dialogue in dialogues[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                speaker = dialogue.speaker or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                text = dialogue.content[:50] + "..." if len(dialogue.content) > 50 else dialogue.content
                logger.info(f"   {speaker}: {text}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º NLP –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        logger.info("\nüß† –¢–µ—Å—Ç–∏—Ä—É–µ–º NLP –æ–±—Ä–∞–±–æ—Ç–∫—É...")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é –ë–î
        db: Session = next(get_db())
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä NLP
            nlp_processor = get_nlp_processor()
            
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –≤ –ë–î (–µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç)
            test_text = text_crud.get_by_filename(db, filename=fb2_file.name)
            if not test_text:
                from app.schemas.text import TextCreate
                text_create = TextCreate(
                    filename=fb2_file.name,
                    content=structured_content.raw_content,
                    project_id=1  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –µ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç —Å ID 1
                )
                test_text = text_crud.create(db, obj_in=text_create)
                logger.info(f"–°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –≤ –ë–î —Å ID: {test_text.id}")
            else:
                logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç–µ–∫—Å—Ç —Å ID: {test_text.id}")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            result = await nlp_processor.process_structured_content(
                structured_content, test_text.id, db
            )
            
            logger.success(f"‚úÖ NLP –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            logger.info(f"üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
            logger.info(f"   –ù–∞–π–¥–µ–Ω–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(result.characters)}")
            logger.info(f"   –†–µ—á–µ–≤—ã—Ö –∞—Ç—Ä–∏–±—É—Ü–∏–π: {len(result.speech_attributions)}")
            logger.info(f"   –ú–µ—Ç–æ–¥: {result.extraction_stats.method_used}")
            logger.info(f"   –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.extraction_stats.extraction_time:.2f}—Å")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
            if result.characters:
                logger.info(f"üé≠ –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏:")
                for char in sorted(result.characters, key=lambda x: x.importance_score, reverse=True)[:10]:
                    logger.info(f"   ‚Ä¢ {char.name} (–≤–∞–∂–Ω–æ—Å—Ç—å: {char.importance_score:.2f}, –∏—Å—Ç–æ—á–Ω–∏–∫: {char.source})")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ—á–µ–≤—ã–µ –∞—Ç—Ä–∏–±—É—Ü–∏–∏
            if result.speech_attributions:
                logger.info(f"üí¨ –†–µ—á–µ–≤—ã–µ –∞—Ç—Ä–∏–±—É—Ü–∏–∏:")
                speech_by_char = {}
                for speech in result.speech_attributions:
                    char_name = speech.character_name
                    speech_by_char[char_name] = speech_by_char.get(char_name, 0) + 1
                
                for char_name, count in sorted(speech_by_char.items(), key=lambda x: x[1], reverse=True)[:10]:
                    logger.info(f"   ‚Ä¢ {char_name}: {count} —Ä–µ–ø–ª–∏–∫")
            
            logger.success("üéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ!")
            
        finally:
            db.close()
    
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()

async def compare_old_vs_new():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ –∏ –Ω–æ–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥–æ–≤"""
    
    logger.info("\n=== –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ –∏ –Ω–æ–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥–æ–≤ ===")
    
    fb2_file = Path(__file__).parent.parent.parent / "books" / "fb2" / "15) 1896 - –î—è–¥—è –í–∞–Ω—è.fb2"
    
    if not fb2_file.exists():
        logger.warning("–§–∞–π–ª –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    try:
        # –°—Ç–∞—Ä—ã–π –ø–æ–¥—Ö–æ–¥
        logger.info("üîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–π –ø–æ–¥—Ö–æ–¥...")
        old_result = fb2_parser.parse_file(str(fb2_file))
        old_content = old_result['content']
        
        # –ù–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥
        logger.info("üîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥...")
        new_content = fb2_parser.parse_to_structured_content(str(fb2_file))
        
        logger.info("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
        logger.info(f"   –°—Ç–∞—Ä—ã–π: –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ {len(old_content)} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"   –ù–æ–≤—ã–π: {len(new_content.elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤, {len(new_content.raw_content)} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"   –ù–æ–≤—ã–π: {len(new_content.get_dialogues())} –¥–∏–∞–ª–æ–≥–æ–≤, {len(new_content.get_character_lists())} —Å–ø–∏—Å–∫–æ–≤ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–∞–∑–ª–∏—á–∏—è –≤ —Ç–µ–∫—Å—Ç–µ
        text_diff = abs(len(old_content) - len(new_content.raw_content))
        logger.info(f"   –†–∞–∑–Ω–∏—Ü–∞ –≤ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞: {text_diff} —Å–∏–º–≤–æ–ª–æ–≤")
        
        if text_diff < 100:
            logger.success("‚úÖ –¢–µ–∫—Å—Ç—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã")
        else:
            logger.warning("‚ö†Ô∏è –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ —Ç–µ–∫—Å—Ç–µ")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏: {e}")

if __name__ == "__main__":
    asyncio.run(test_structured_content_parsing())
    asyncio.run(compare_old_vs_new())
