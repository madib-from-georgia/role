#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ EPUB —Ñ–∞–π–ª–∞ "–î—è–¥—è –í–∞–Ω—è"
"""

import sys
import os
sys.path.append('backend')

from backend.app.parsers.epub_parser import EPUBParser
from backend.app.services.nlp.extractors.character_extractor import CharacterExtractor
import asyncio

def test_epub_parsing():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ EPUB —Ñ–∞–π–ª–∞"""

    epub_file = "../../books/epub/–ß–µ—Ö–æ–≤ –ê–Ω—Ç–æ–Ω. –î—è–¥—è –í–∞–Ω—è - royallib.com.epub"

    if not os.path.exists(epub_file):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {epub_file}")
        return

    print(f"üìñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª: {epub_file}")
    print("=" * 80)

    # 1. –ü–∞—Ä—Å–∏–º EPUB —Ñ–∞–π–ª
    parser = EPUBParser()

    try:
        result = parser.parse_file(epub_file)
        content = result['content']
        metadata = result['metadata']

        print(f"‚úÖ EPUB —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω")
        print(f"üìä –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
        lines_count = len(content.split('\n'))
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {lines_count}")
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {len(content.split())}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2000 —Å–∏–º–≤–æ–ª–æ–≤
        print("\n" + "=" * 80)
        print("üîç –ü–ï–†–í–´–ï 2000 –°–ò–ú–í–û–õ–û–í –ö–û–ù–¢–ï–ù–¢–ê:")
        print("=" * 80)
        print(content[:2000])
        print("..." if len(content) > 2000 else "")

        # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤—Ä—É—á–Ω—É—é
        print("\n" + "=" * 80)
        print("üîç –ü–û–ò–°–ö –ü–ï–†–°–û–ù–ê–ñ–ï–ô –í –¢–ï–ö–°–¢–ï:")
        print("=" * 80)

        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏ –∏–∑ "–î—è–¥–∏ –í–∞–Ω–∏"
        expected_characters = [
            "–°–µ—Ä–µ–±—Ä—è–∫–æ–≤", "–ê–ª–µ–∫—Å–∞–Ω–¥—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á",
            "–ï–ª–µ–Ω–∞ –ê–Ω–¥—Ä–µ–µ–≤–Ω–∞", "–ï–ª–µ–Ω–∞",
            "–í–æ–π–Ω–∏—Ü–∫–∏–π", "–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤–∏—á", "–í–∞–Ω—è",
            "–°–æ–Ω—è", "–°–æ—Ñ–∏—è –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–Ω–∞",
            "–í–æ–π–Ω–∏—Ü–∫–∞—è", "–ú–∞—Ä–∏—è –í–∞—Å–∏–ª—å–µ–≤–Ω–∞",
            "–ê—Å—Ç—Ä–æ–≤", "–ú–∏—Ö–∞–∏–ª –õ—å–≤–æ–≤–∏—á",
            "–¢–µ–ª–µ–≥–∏–Ω", "–ò–ª—å—è –ò–ª—å–∏—á", "–í–∞—Ñ–ª—è",
            "–ú–∞—Ä–∏–Ω–∞", "–ï—Ñ–∏–º"
        ]

        for char in expected_characters:
            count = content.lower().count(char.lower())
            if count > 0:
                print(f"  ‚úÖ {char}: {count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π")
            else:
                print(f"  ‚ùå {char}: –Ω–µ –Ω–∞–π–¥–µ–Ω")

        # –ò—â–µ–º —Å–µ–∫—Ü–∏—é "–î–µ–π—Å—Ç–≤—É—é—â–∏–µ –ª–∏—Ü–∞"
        print("\n" + "=" * 80)
        print("üîç –ü–û–ò–°–ö –°–ï–ö–¶–ò–ò '–î–ï–ô–°–¢–í–£–Æ–©–ò–ï –õ–ò–¶–ê':")
        print("=" * 80)

        import re
        patterns = [
            r"(?i)–¥–µ–π—Å—Ç–≤—É—é—â–∏–µ\s+–ª–∏—Ü–∞",
            r"(?i)–î–ï–ô–°–¢–í–£–Æ–©–ò–ï\s+–õ–ò–¶–ê",
            r"(?i)–ª–∏—Ü–∞",
            r"(?i)–ø–µ—Ä—Å–æ–Ω–∞–∂–∏"
        ]

        found_section = False
        for pattern in patterns:
            matches = list(re.finditer(pattern, content))
            if matches:
                found_section = True
                print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω '{pattern}': {len(matches)} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
                for i, match in enumerate(matches[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                    start = max(0, match.start() - 100)
                    end = min(len(content), match.end() + 300)
                    context = content[start:end]
                    print(f"    –ö–æ–Ω—Ç–µ–∫—Å—Ç {i+1}: ...{context}...")
                    print()

        if not found_section:
            print("  ‚ùå –°–µ–∫—Ü–∏—è '–î–µ–π—Å—Ç–≤—É—é—â–∏–µ –ª–∏—Ü–∞' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

        # –ò—â–µ–º –¥–∏–∞–ª–æ–≥–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "–ò–ú–Ø:"
        print("\n" + "=" * 80)
        print("üîç –ü–û–ò–°–ö –î–ò–ê–õ–û–ì–û–í –í –§–û–†–ú–ê–¢–ï '–ò–ú–Ø:':")
        print("=" * 80)

        dialogue_pattern = r'^\s*([–ê-–Ø–Å][–ê-–Ø–Å\s]+):\s*.+$'
        dialogue_matches = re.findall(dialogue_pattern, content, re.MULTILINE)

        if dialogue_matches:
            print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(dialogue_matches)} –¥–∏–∞–ª–æ–≥–æ–≤")
            unique_speakers = set(dialogue_matches)
            print(f"  üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥–æ–≤–æ—Ä—è—â–∏—Ö: {len(unique_speakers)}")
            print("  üë• –ì–æ–≤–æ—Ä—è—â–∏–µ:")
            for speaker in sorted(unique_speakers):
                count = dialogue_matches.count(speaker)
                print(f"    - {speaker}: {count} —Ä–µ–ø–ª–∏–∫")
        else:
            print("  ‚ùå –î–∏–∞–ª–æ–≥–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ '–ò–ú–Ø:' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        # –¢–µ–ø–µ—Ä—å —Ç–µ—Å—Ç–∏—Ä—É–µ–º NLP —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
        print("\n" + "=" * 80)
        print("ü§ñ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï NLP –≠–ö–°–¢–†–ê–ö–¢–û–†–ê:")
        print("=" * 80)

        async def test_character_extraction():
            extractor = CharacterExtractor()
            characters, speech_data, stats = await extractor.extract_characters_and_speech(content)

            print(f"  üìä –ù–∞–π–¥–µ–Ω–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(characters)}")
            print(f"  üìä –ù–∞–π–¥–µ–Ω–æ –∞—Ç—Ä–∏–±—É—Ü–∏–π —Ä–µ—á–∏: {len(speech_data)}")
            print(f"  üìä –ú–µ—Ç–æ–¥: {stats.method_used}")
            print(f"  üìä –§–æ—Ä–º–∞—Ç –ø—å–µ—Å—ã: {stats.is_play_format}")
            print(f"  üìä –ï—Å—Ç—å —Å–µ–∫—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {stats.has_character_section}")

            if characters:
                print("  üë• –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏:")
                for char in characters:
                    print(f"    - {char.name} (–∏—Å—Ç–æ—á–Ω–∏–∫: {char.source}, —É–ø–æ–º–∏–Ω–∞–Ω–∏–π: {char.mentions_count})")
                    if char.description:
                        print(f"      –û–ø–∏—Å–∞–Ω–∏–µ: {char.description}")
            else:
                print("  ‚ùå –ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")

            if stats.processing_errors:
                print("  ‚ö†Ô∏è –û—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
                for error in stats.processing_errors:
                    print(f"    - {error}")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç
        asyncio.run(test_character_extraction())

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ EPUB: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_epub_parsing()
