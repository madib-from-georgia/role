"""
–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä—Å–µ—Ä–æ–≤ —Ñ–∞–π–ª–æ–≤.
"""

from abc import ABC, abstractmethod
from typing import Dict, Any
from pathlib import Path
import logging

from .content_models import StructuredContent, ContentAnalyzer

logger = logging.getLogger(__name__)


class BaseParser(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä—Å–µ—Ä–æ–≤ —Ñ–∞–π–ª–æ–≤."""
    
    def __init__(self):
        self.supported_extensions = []
        self.max_file_size = 50 * 1024 * 1024  # 50MB –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    @abstractmethod
    def parse_file(self, file_path: str) -> Dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ (legacy –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏).
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        pass
    
    @abstractmethod
    def parse_to_structured_content(self, file_path: str) -> StructuredContent:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            –û–±—ä–µ–∫—Ç StructuredContent —Å —Ä–∞–∑–æ–±—Ä–∞–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
        """
        pass
    
    @abstractmethod
    def validate_file(self, file_path: str) -> bool:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            True –µ—Å–ª–∏ —Ñ–∞–π–ª –≤–∞–ª–∏–¥–µ–Ω, False –∏–Ω–∞—á–µ
        """
        pass
    
    def _validate_basic(self, file_path: str) -> bool:
        """–ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞."""
        try:
            file_path_obj = Path(file_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            if not file_path_obj.exists():
                logger.error(f"–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {file_path}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = file_path_obj.stat().st_size
            if file_size > self.max_file_size:
                logger.error(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file_size} –±–∞–π—Ç (–º–∞–∫—Å–∏–º—É–º {self.max_file_size})")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
            if self.supported_extensions and file_path_obj.suffix.lower() not in self.supported_extensions:
                logger.warning(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {file_path_obj.suffix}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
            if file_size == 0:
                logger.error("–§–∞–π–ª –ø—É—Å—Ç–æ–π")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –±–∞–∑–æ–≤–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return False
    
    def _extract_basic_metadata(self, file_path: str, content: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
        file_path_obj = Path(file_path)
        
        return {
            'filename': file_path_obj.name,
            'file_size': file_path_obj.stat().st_size if file_path_obj.exists() else 0,
            'character_count': len(content),
            'word_count': len(content.split()),
            'line_count': len(content.split('\n')),
            'format': file_path_obj.suffix.lower().lstrip('.')
        }
    
    def _normalize_play_content(self, raw_content: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—ã—Ä–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø—å–µ—Å—ã –¥–ª—è —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞.
        –ü—Ä–∏–≤–æ–¥–∏—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –ø—å–µ—Å –∫ –µ–¥–∏–Ω–æ–º—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É.
        """
        import re
        
        if not raw_content:
            return ""
        
        # 1. –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
        content = raw_content.strip()
        
        # 2. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ (–æ—Å—Ç–∞–≤–ª—è–µ–º –º–∞–∫—Å–∏–º—É–º 2 –ø–æ–¥—Ä—è–¥)
        content = re.sub(r'\n{3,}', '\n\n', content)
        
        # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π –∏ —è–≤–ª–µ–Ω–∏–π
        content = self._normalize_act_headers(content)
        
        # 4. –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–º–∞—Ä–∫–∏ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ —Ä–µ–ø–ª–∏–∫–∏
        content = self._normalize_stage_directions(content)
        
        # 5. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–µ–∑—ã–º—è–Ω–Ω—ã–µ —Ä–µ–ø–ª–∏–∫–∏ (–ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –≥–æ–≤–æ—Ä—è—â–µ–º—É)
        content = self._assign_orphan_speeches(content)
        
        # 6. –ü–æ—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∏–∞–ª–æ–≥–∏ –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
        content = self._normalize_dialogue_format(content)
        
        # 7. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–µ–º–∞—Ä–∫–∏ –≤–Ω—É—Ç—Ä–∏ —Ä–µ–ø–ª–∏–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        content = self._normalize_inline_stage_directions(content)
        
        # 8. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ø–∏—Å–∫–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        content = self._normalize_character_lists(content)
        
        # 9. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        content = self._final_cleanup(content)
        
        return content

    def _normalize_act_headers(self, content: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–µ–π—Å—Ç–≤–∏–π –∏ —è–≤–ª–µ–Ω–∏–π"""
        import re
        lines = content.split('\n')
        normalized_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                normalized_lines.append('')
                continue
                
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π
            if re.match(r'(?i)(–¥–µ–π—Å—Ç–≤–∏–µ|–∞–∫—Ç)\s*(–ø–µ—Ä–≤–æ–µ|–≤—Ç–æ—Ä–æ–µ|—Ç—Ä–µ—Ç—å–µ|—á–µ—Ç–≤–µ—Ä—Ç–æ–µ|–ø—è—Ç–æ–µ|\d+)', line):
                line = re.sub(r'\s+', ' ', line).title()
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —è–≤–ª–µ–Ω–∏–π
            elif re.match(r'(?i)(—è–≤–ª–µ–Ω–∏–µ|—Å—Ü–µ–Ω–∞)\s*(–ø–µ—Ä–≤–æ–µ|–≤—Ç–æ—Ä–æ–µ|—Ç—Ä–µ—Ç—å–µ|\d+)', line):
                line = re.sub(r'\s+', ' ', line).title()
            
            normalized_lines.append(line)
        
        return '\n'.join(normalized_lines)

    def _normalize_dialogue_format(self, content: str) -> str:
        """
        –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∏–∞–ª–æ–≥–æ–≤ –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É: "–ò–ú–Ø: —Ç–µ–∫—Å—Ç"
        """
        import re
        lines = content.split('\n')
        normalized_lines = []
        
        for line in lines:
            line = line.strip()
            
            if not line:
                normalized_lines.append('')
                continue
            
                        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–∏–∞–ª–æ–≥–æ–≤
            dialogue_patterns = [
                # "–ò–ú–Ø (–¥–µ–π—Å—Ç–≤–∏–µ). –¢–µ–∫—Å—Ç" -> "–ò–ú–Ø (–¥–µ–π—Å—Ç–≤–∏–µ): –¢–µ–∫—Å—Ç" (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤ —Å–∫–æ–±–∫–∞—Ö)
                (r'^([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]+?\s*\([^)]+\))\s*\.\s*(.+)$', r'\1: \2'),

                # "–ò–ú–Ø. –¢–µ–∫—Å—Ç" -> "–ò–ú–Ø: –¢–µ–∫—Å—Ç" (–≤—Å–µ–≥–¥–∞ —Å—Ç–∞–≤–∏–º —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª)
                (r'^([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]+?)\s*\.\s*(.+)$', r'\1: \2'),

                # "‚Äî –¢–µ–∫—Å—Ç, ‚Äî –≥–æ–≤–æ—Ä–∏—Ç –ò–ú–Ø." -> "–ò–ú–Ø: –¢–µ–∫—Å—Ç"
                (r'^‚Äî\s*(.+?),?\s*‚Äî\s*([–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)*)\.$', r'\2: \1'),

                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–≤–æ–µ—Ç–æ—á–∏—è (—É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã)
                (r'^([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]+?)\s*:\s*(.+)$', r'\1: \2'),
            ]

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            for pattern, replacement in dialogue_patterns:
                if re.match(pattern, line):
                    line = re.sub(pattern, replacement, line)
                    break
            
            # –ó–∞–∫–ª—é—á–∞–µ–º —Ä–µ–º–∞—Ä–∫–∏ –≤ –∏–º–µ–Ω–∞—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ [[]]
            line = self._normalize_speaker_stage_directions(line)
            
            normalized_lines.append(line)
        
        return '\n'.join(normalized_lines)
    
    def _normalize_speaker_stage_directions(self, line: str) -> str:
        """
        –ó–∞–∫–ª—é—á–∞–µ—Ç —Ä–µ–º–∞—Ä–∫–∏ –≤ –∏–º–µ–Ω–∞—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ [[]]
        –ù–∞–ø—Ä–∏–º–µ—Ä: "–ú–∞—Ä–∏–Ω–∞ (–Ω–∞–ª–∏–≤–∞–µ—Ç —Å—Ç–∞–∫–∞–Ω): —Ç–µ–∫—Å—Ç" -> "–ú–∞—Ä–∏–Ω–∞ [[–Ω–∞–ª–∏–≤–∞–µ—Ç —Å—Ç–∞–∫–∞–Ω]]: —Ç–µ–∫—Å—Ç"
        """
        import re
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–º–∞—Ä–æ–∫ –≤ —Å–∫–æ–±–∫–∞—Ö –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ (–∏–º—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞)
        # –ò—â–µ–º "–ò–ú–Ø (—Ä–µ–º–∞—Ä–∫–∞): —Ç–µ–∫—Å—Ç" –∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ "–ò–ú–Ø [[—Ä–µ–º–∞—Ä–∫–∞]]: —Ç–µ–∫—Å—Ç"
        pattern = r'^([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]*?)\s*\(([^)]+)\)\s*:\s*(.+)$'
        match = re.match(pattern, line)
        
        if match:
            speaker_name = match.group(1).strip()
            stage_direction = match.group(2).strip()
            speech_text = match.group(3).strip()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É —Å —Ä–µ–º–∞—Ä–∫–æ–π –≤ [[]]
            return f"{speaker_name} [[{stage_direction}]]: {speech_text}"
        
        return line
    
    def _normalize_inline_stage_directions(self, content: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ä–µ–º–∞—Ä–∫–∏ –≤–Ω—É—Ç—Ä–∏ —Ä–µ–ø–ª–∏–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        –ó–∞–º–µ–Ω—è–µ—Ç (–¥–µ–π—Å—Ç–≤–∏–µ) –Ω–∞ [[–¥–µ–π—Å—Ç–≤–∏–µ]] –≤ —Ç–µ–∫—Å—Ç–µ —Ä–µ–ø–ª–∏–∫
        """
        import re
        lines = content.split('\n')
        normalized_lines = []
        
        for line in lines:
            original_line = line.strip()
            
            if not original_line:
                normalized_lines.append('')
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —Ä–µ–ø–ª–∏–∫–æ–π –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            if self._is_character_line(original_line):
                # –ó–∞–º–µ–Ω—è–µ–º —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö –≤–Ω—É—Ç—Ä–∏ —Ä–µ—á–∏ –Ω–∞ [[]]
                normalized_line = self._replace_inline_parentheses(original_line)
                normalized_lines.append(normalized_line)
            else:
                normalized_lines.append(original_line)
        
        return '\n'.join(normalized_lines)
    
    def _replace_inline_parentheses(self, line: str) -> str:
        """
        –ó–∞–º–µ–Ω—è–µ—Ç —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö –≤–Ω—É—Ç—Ä–∏ —Ä–µ–ø–ª–∏–∫–∏ –Ω–∞ [[]]
        –ù–æ –ù–ï —Ç—Ä–æ–≥–∞–µ—Ç —Å–∫–æ–±–∫–∏ –≤ –∏–º–µ–Ω–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
        """
        import re
        
        # –ù–∞—Ö–æ–¥–∏–º –≥—Ä–∞–Ω–∏—Ü—É –º–µ–∂–¥—É –∏–º–µ–Ω–µ–º –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –∏ –µ–≥–æ —Ä–µ—á—å—é
        # –ë–µ—Ä–µ–º –≤—Å–µ –¥–æ –ø–µ—Ä–≤–æ–≥–æ –¥–≤–æ–µ—Ç–æ—á–∏—è –∫–∞–∫ –∏–º—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
        match = re.match(r'^([^:]+?):\s*(.+)$', line)
        
        if match:
            speaker_part = match.group(1)  # –ò–º—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ (—É–∂–µ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å [[]])
            speech_part = match.group(2)   # –†–µ—á—å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            
            # –í —Ä–µ—á–µ–≤–æ–π —á–∞—Å—Ç–∏ –∑–∞–º–µ–Ω—è–µ–º (—Ç–µ–∫—Å—Ç) –Ω–∞ [[—Ç–µ–∫—Å—Ç]]
            # –ò—â–µ–º —Å–∫–æ–±–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ä–µ–º–∞—Ä–∫–∏ (–æ–±—ã—á–Ω–æ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –≥–ª–∞–≥–æ–ª—ã)
            def replace_stage_direction(match):
                content = match.group(1).strip()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂–µ –ª–∏ —ç—Ç–æ –Ω–∞ —Ä–µ–º–∞—Ä–∫—É
                if self._looks_like_stage_direction(content):
                    return f"[[{content}]]"
                else:
                    # –û—Å—Ç–∞–≤–ª—è–µ–º –æ–±—ã—á–Ω—ã–µ —Å–∫–æ–±–∫–∏ –∫–∞–∫ –µ—Å—Ç—å
                    return f"({content})"
            
            # –ó–∞–º–µ–Ω—è–µ–º —Å–∫–æ–±–∫–∏ –≤ —Ä–µ—á–µ–≤–æ–π —á–∞—Å—Ç–∏
            normalized_speech = re.sub(r'\(([^)]+)\)', replace_stage_direction, speech_part)
            
            # –¢–∞–∫–∂–µ –∏—â–µ–º –¥–µ–π—Å—Ç–≤–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ –∫–æ–Ω—Ü–µ —Ä–µ–ø–ª–∏–∫–∏ (–Ω–µ –≤ —Å–∫–æ–±–∫–∞—Ö)
            # –ü–∞—Ç—Ç–µ—Ä–Ω: "–ò–º—è –≥–ª–∞–≥–æ–ª" –≤ –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            action_pattern = r'\.?\s*([–ê-–Ø–Å][–∞-—è—ë\s]{1,25}\s+(—Ç–∏—Ö–æ\s+|–≥—Ä–æ–º–∫–æ\s+|–º–µ–¥–ª–µ–Ω–Ω–æ\s+)?(–Ω–∞–∏–≥—Ä—ã–≤–∞–µ—Ç|–∏–≥—Ä–∞–µ—Ç|–ø–æ–µ—Ç|–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç|—Ö–æ–¥–∏—Ç|—Å–∞–¥–∏—Ç—Å—è|–≤—Å—Ç–∞–µ—Ç|—É—Ö–æ–¥–∏—Ç|–≤—Ö–æ–¥–∏—Ç|–≤—ã—Ö–æ–¥–∏—Ç|–±–µ—Ä–µ—Ç|–¥–∞–µ—Ç|–ø—å–µ—Ç|—Å–º–æ—Ç—Ä–∏—Ç|—Å–º–µ–µ—Ç—Å—è|–ø–ª–∞—á–µ—Ç|–æ–±–Ω–∏–º–∞–µ—Ç)[^.]*)\.$'
            
            match_action = re.search(action_pattern, normalized_speech)
            if match_action:
                action_text = match_action.group(1).strip()
                # –£–±–∏—Ä–∞–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –∏–∑ —Ä–µ—á–∏ –∏ –¥–µ–ª–∞–µ–º –µ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ä–µ–º–∞—Ä–∫–æ–π
                speech_without_action = re.sub(action_pattern, '.', normalized_speech).strip()
                if speech_without_action.endswith('..'):
                    speech_without_action = speech_without_action[:-1]  # —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω—é—é —Ç–æ—á–∫—É
                
                return f"{speaker_part}: {speech_without_action}\n[[{action_text}]]"
            
            return f"{speaker_part}: {normalized_speech}"
        
        return line
    
    def _looks_like_stage_direction(self, text: str) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –≤ —Å–∫–æ–±–∫–∞—Ö —Ä–µ–º–∞—Ä–∫–æ–π
        """
        import re
        
        # –¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–µ–º–∞—Ä–æ–∫ - —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
        stage_direction_patterns = [
            # –î–≤–∏–∂–µ–Ω–∏—è –∏ –ø–æ–∑—ã
            r'[–ó–∑]–µ–≤–∞–µ—Ç',
            r'[–í–≤]—Ö–æ–¥–∏—Ç',
            r'[–í–≤]—ã—Ö–æ–¥–∏—Ç', 
            r'[–°—Å]–∞–¥–∏—Ç—Å—è',
            r'[–í–≤]—Å—Ç–∞–µ—Ç',
            r'[–£—É]—Ö–æ–¥–∏—Ç',
            r'[–ü–ø]–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç—Å—è',
            r'[–ù–Ω]–∞–∫–ª–æ–Ω—è–µ—Ç—Å—è',
            r'[–û–æ]–≥–ª—è–¥—ã–≤–∞–µ—Ç—Å—è',
            r'[–ü–ø]–æ–¥—Ö–æ–¥–∏—Ç',
            r'[–û–æ]—Ç—Ö–æ–¥–∏—Ç',
            r'[–ü–ø]–µ—Ä–µ—Å—Ç–∞–Ω–µ—Ç',
            r'[–ü–ø]—Ä–æ–¥–æ–ª–∂–∞–µ—Ç',
            
            # –î–µ–π—Å—Ç–≤–∏—è —Å –ø—Ä–µ–¥–º–µ—Ç–∞–º–∏
            r'[–ë–±]–µ—Ä–µ—Ç',
            r'[–î–¥]–µ—Ä–∂–∏—Ç',
            r'[–û–æ]—Ç–∫—Ä—ã–≤–∞–µ—Ç',
            r'[–ó–∑]–∞–∫—Ä—ã–≤–∞–µ—Ç',
            r'[–ü–ø]—Ä–æ—Ç—è–≥–∏–≤–∞–µ—Ç',
            r'[–ü–ø]–æ–¥–∞–µ—Ç',
            r'[–°—Å]—Ç–∞–≤–∏—Ç',
            r'[–ö–∫]–ª–∞–¥–µ—Ç',
            r'[–ù–Ω]–∞–ª–∏–≤–∞–µ—Ç',
            r'[–ü–ø]—å–µ—Ç',
            r'[–ï–µ]—Å—Ç',
            r'[–ß—á]–∏—Ç–∞–µ—Ç',
            r'[–ü–ø]–∏—à–µ—Ç',
            r'[–ò–∏]—â–µ—Ç',
            r'[–û–æ]—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç',
            r'[–¢—Ç]—Ä–æ–≥–∞–µ—Ç',
            r'[–î–¥]–æ—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç—Å—è',
            
            # –í–∑–≥–ª—è–¥—ã –∏ –∂–µ—Å—Ç—ã
            r'[–°—Å]–º–æ—Ç—Ä–∏—Ç',
            r'[–ü–ø]–æ–∫–∞–∑—ã–≤–∞–µ—Ç',
            r'[–î–¥]–µ–ª–∞–µ—Ç',
            r'[–ö–∫]–∏–≤–∞–µ—Ç',
            r'[–ö–∫]–∞—á–∞–µ—Ç\s+–≥–æ–ª–æ–≤–æ–π',
            r'[–ü–ø]–æ–∂–∏–º–∞–µ—Ç\s+–ø–ª–µ—á–∞–º–∏',
            r'[–û–æ]–±–Ω–∏–º–∞–µ—Ç',
            r'[–¶—Ü]–µ–ª—É–µ—Ç',
            r'[–ü–ø]—Ä–∏–∂–∏–º–∞–µ—Ç',
            r'[–î–¥]–µ—Ä–∂–∏—Ç\s+–∑–∞\s+—Ä—É–∫—É',
            
            # –†–µ—á–µ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
            r'[–ì–≥]–æ–≤–æ—Ä–∏—Ç',
            r'[–ö–∫]—Ä–∏—á–∏—Ç',
            r'[–®—à]–µ–ø—á–µ—Ç',
            r'[–í–≤]–æ—Å–∫–ª–∏—Ü–∞–µ—Ç',
            r'[–û–æ]—Ç–≤–µ—á–∞–µ—Ç',
            r'[–ü–ø]–µ—Ä–µ–±–∏–≤–∞–µ—Ç',
            r'[–°—Å]–º–µ–µ—Ç—Å—è',
            r'[–ü–ø]–ª–∞—á–µ—Ç',
            r'[–í–≤]–∑–¥—ã—Ö–∞–µ—Ç',
            
            # –ú—É–∑—ã–∫–∞–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
            r'[–ù–Ω]–∞–∏–≥—Ä—ã–≤–∞–µ—Ç',
            r'[–ò–∏]–≥—Ä–∞–µ—Ç',
            r'[–ü–ø]–æ–µ—Ç',
            r'[–ù–Ω]–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç',
            
            # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –Ω–∞—Ä–µ—á–∏—è
            r'—Ç–∏—Ö–æ|–≥—Ä–æ–º–∫–æ|–±—ã—Å—Ç—Ä–æ|–º–µ–¥–ª–µ–Ω–Ω–æ|–Ω–µ–∂–Ω–æ|–≥—Ä—É–±–æ|—Å–µ—Ä–¥–∏—Ç–æ',
            r'—Å\s+(–¥–æ—Å–∞–¥–æ–π|—Ä–∞–¥–æ—Å—Ç—å—é|–≥—Ä—É—Å—Ç—å—é|—É–¥–∏–≤–ª–µ–Ω–∏–µ–º|–≥–Ω–µ–≤–æ–º|—É–ª—ã–±–∫–æ–π)',
            r'–≤–µ—Å–µ–ª–æ|–ø–µ—á–∞–ª—å–Ω–æ|–∑–∞–¥—É–º—á–∏–≤–æ|—Ä–∞—Å—Å–µ—è–Ω–Ω–æ|–≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ',
            r'–≤\s+(–Ω–µ–¥–æ—É–º–µ–Ω–∏–∏|—É–∂–∞—Å–µ|–≤–æ—Å—Ç–æ—Ä–≥–µ|—Å–º—É—â–µ–Ω–∏–∏|–≥–Ω–µ–≤–µ|–ø–µ—á–∞–ª–∏)',
            r'—Å–∫—Ä–µ—Å—Ç–∏–≤\s+—Ä—É–∫–∏',
            r'–Ω–∞–≥–Ω—É–≤\s+–≥–æ–ª–æ–≤—É',
            r'–ø–æ–¥–±–æ—á–µ–Ω—è—Å—å',
            
            # –£–∫–∞–∑–∞–Ω–∏—è –º–µ—Å—Ç–∞ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            r'–≤\s+—Å—Ç–æ—Ä–æ–Ω—É|–∑–∞\s+—Å—Ü–µ–Ω|–∏–∑-–∑–∞|–≥–ª–∞–∑–∞–º–∏',
            r'–∫\s+(–æ–∫–Ω—É|–¥–≤–µ—Ä–∏|—Å—Ç–æ–ª—É)|–æ—Ç\s+(–æ–∫–Ω–∞|–¥–≤–µ—Ä–∏|—Å—Ç–æ–ª–∞)',
            r'–Ω–∞–ø—Ä–∞–≤–æ|–Ω–∞–ª–µ–≤–æ|–≤–≤–µ—Ä—Ö|–≤–Ω–∏–∑|—Ç—É–¥–∞|—Å—é–¥–∞',
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —É–∫–∞–∑–∞–Ω–∏—è
            r'–ø–æ—Å–ª–µ\s+–ø–∞—É–∑—ã|—á–µ—Ä–µ–∑\s+–º–∏–Ω—É—Ç—É|–≤–¥—Ä—É–≥|–≤–Ω–µ–∑–∞–ø–Ω–æ',
            
            # –û–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            r'^[–ê-–Ø–Å][–∞-—è—ë]+\.$',  # –°–ª–æ–≤–æ —Å —Ç–æ—á–∫–æ–π –≤ –∫–æ–Ω—Ü–µ
        ]
        
        for pattern in stage_direction_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        
        # –£–±–∏—Ä–∞–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –¥–ª–∏–Ω–µ - —Ä–µ–º–∞—Ä–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –ª—é–±–æ–π –¥–ª–∏–Ω—ã
        # –ü–æ–ª–∞–≥–∞–µ–º—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–µ–π—Å—Ç–≤–∏–π –∏ —ç–º–æ—Ü–∏–π
        return False
    
    def _assign_orphan_speeches(self, content: str) -> str:
        """
        –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç –±–µ–∑—ã–º—è–Ω–Ω—ã–µ —Ä–µ–ø–ª–∏–∫–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –≥–æ–≤–æ—Ä—è—â–µ–º—É
        """
        import re
        lines = content.split('\n')
        normalized_lines = []
        last_speaker = None
        
        for line in lines:
            original_line = line
            line = line.strip()
            
            if not line:
                normalized_lines.append('')
                continue
            
            # –°–ù–ê–ß–ê–õ–ê –ø—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —Ä–µ–º–∞—Ä–∫–æ–π (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤—ã—à–µ!)
            if self._is_stage_direction_line(line):
                normalized_lines.append(line)
                continue
            
            # –ü–û–¢–û–ú –ø—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç –ª–∏ —ç—Ç–æ –±—ã—Ç—å –±–µ–∑—ã–º—è–Ω–Ω–æ–π —Ä–µ–ø–ª–∏–∫–æ–π
            if self._is_orphan_speech(line) and last_speaker:
                # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –≥–æ–≤–æ—Ä—è—â–µ–º—É
                assigned_line = f"{last_speaker}: {line}"
                normalized_lines.append(assigned_line)
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —Ä–µ–ø–ª–∏–∫–æ–π —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            if self._is_character_line(line):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –≥–æ–≤–æ—Ä—è—â–µ–≥–æ (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å –¥–≤–æ–µ—Ç–æ—á–∏–µ–º –∏–ª–∏ —Ç–æ—á–∫–æ–π, —Å [[]] –∏–ª–∏ ())
                speaker_match = (
                    re.match(r'^([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]*(?:\[\[[^\]]+\]\])?[–ê-–Ø–Å–∞-—è—ë\s]*?):\s*(.+)$', line) or
                    re.match(r'^([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]*(?:\([^)]+\))?[–ê-–Ø–Å–∞-—è—ë\s]*?):\s*(.+)$', line) or
                    re.match(r'^([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]*(?:\([^)]+\))?)\s*\.\s*(.+?)(?:\s*\[\[[^\]]+\]\])?$', line) or  # —Å [[]] –≤ –∫–æ–Ω—Ü–µ
                    re.match(r'^([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]*(?:\([^)]+\))?)\s*\.\s*(.+)$', line)  # –±–µ–∑ [[]] –≤ –∫–æ–Ω—Ü–µ
                )
                if speaker_match:
                    speaker_part = speaker_match.group(1).strip()
                    # –û—á–∏—â–∞–µ–º –æ—Ç –¥–µ–π—Å—Ç–≤–∏–π –≤ —Å–∫–æ–±–∫–∞—Ö –∏ [[]] –¥–ª—è –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
                    clean_speaker = re.sub(r'\s*\([^)]+\)\s*', '', speaker_part)
                    clean_speaker = re.sub(r'\s*\[\[[^\]]+\]\]\s*', '', clean_speaker).strip()
                    last_speaker = clean_speaker
                
                normalized_lines.append(line)
                continue
            
            # –ò–Ω–∞—á–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            normalized_lines.append(line)
        
        return '\n'.join(normalized_lines)
    
    def _is_orphan_speech(self, line: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –±–µ–∑—ã–º—è–Ω–Ω–æ–π —Ä–µ–ø–ª–∏–∫–æ–π"""
        import re
        
        # –û–¥–Ω–æ—Å–ª–æ–∂–Ω—ã–µ —Ñ—Ä–∞–∑—ã —Å –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ–º
        if re.match(r'^[–ê-–Ø–Å][–∞-—è—ë]{0,3}\.\.\.?\s*$', line):
            return True
        
        # –ö–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å–æ —Å—Ç—Ä–æ—á–Ω–æ–π –±—É–∫–≤—ã
        if re.match(r'^[–∞-—è—ë].{1,20}$', line):
            return True
        
        # –§—Ä–∞–∑—ã —Å –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ–º –≤ –∫–æ–Ω—Ü–µ
        if re.match(r'^[–ê-–Ø–Å][–∞-—è—ë\s]{1,30}\.\.\.?\s*$', line):
            return True
        
        # –í–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è –∏ –º–µ–∂–¥–æ–º–µ—Ç–∏—è
        if re.match(r'^[–ê-–Ø–Å][–∞-—è—ë]{0,6}[!\?\.]*\s*$', line):
            return True
        
        return False

    def _normalize_character_lists(self, content: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–∏—Å–∫–æ–≤ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π"""
        import re
        lines = content.split('\n')
        normalized_lines = []
        in_character_list = False
        
        for line in lines:
            line = line.strip()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π (—Ç–æ–ª—å–∫–æ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏, –Ω–µ –≤ —Ä–µ–ø–ª–∏–∫–∞—Ö)
            if (re.match(r'(?i)^\s*(–¥–µ–π—Å—Ç–≤—É—é—â–∏–µ\s+–ª–∏—Ü–∞|–ø–µ—Ä—Å–æ–Ω–∞–∂–∏|–¥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∏–µ\s+–ª–∏—Ü–∞)\s*:?\s*$', line) and 
                not self._is_character_line(line)):
                in_character_list = True
                line = "–î–ï–ô–°–¢–í–£–Æ–©–ò–ï –õ–ò–¶–ê:"
                normalized_lines.append('')
                normalized_lines.append(line)
                normalized_lines.append('')
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
            if in_character_list and (
                re.search(r'(?i)(–¥–µ–π—Å—Ç–≤–∏–µ|–∞–∫—Ç|—è–≤–ª–µ–Ω–∏–µ|—Å—Ü–µ–Ω–∞)', line) or
                line.startswith('–î–µ–π—Å—Ç–≤–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç')
            ):
                in_character_list = False
                normalized_lines.append('')
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
            if in_character_list and line:
                # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ
                line = re.sub(r'\s+', ' ', line).rstrip('.')
                
            normalized_lines.append(line)
        
        return '\n'.join(normalized_lines)

    def _normalize_stage_directions(self, content: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–º–∞—Ä–æ–∫ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã—Ö —Ä–µ–ø–ª–∏–∫
        """
        import re
        lines = content.split('\n')
        normalized_lines = []
        i = 0
        
        while i < len(lines):
            line = lines[i].strip()
            
            if not line:
                normalized_lines.append('')
                i += 1
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –Ω–∞—á–∞–ª–æ–º —Ä–µ–ø–ª–∏–∫–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            if self._is_character_line(line):
                # –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ä–µ–ø–ª–∏–∫–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
                character_speech = line
                i += 1
                
                # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–µ–ø–ª–∏–∫–∏, –≤–∫–ª—é—á–∞—è —Ä–µ–º–∞—Ä–∫–∏
                while i < len(lines):
                    next_line = lines[i].strip()
                    
                    # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–æ–∏—Å–∫
                    if not next_line:
                        i += 1
                        continue
                    
                    # –ï—Å–ª–∏ —ç—Ç–æ –Ω–æ–≤–∞—è —Ä–µ–ø–ª–∏–∫–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ - –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º
                    if self._is_character_line(next_line):
                        break
                    
                    # –ï—Å–ª–∏ —ç—Ç–æ —Ä–µ–º–∞—Ä–∫–∞ - —Ä–∞–∑–ª–∏—á–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ –¥–ª–∏–Ω–Ω—ã–µ/–∞–≤—Ç–æ—Ä—Å–∫–∏–µ —Ä–µ–º–∞—Ä–∫–∏
                    if self._is_stage_direction_line(next_line):
                        # –ö–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–º–∞—Ä–∫–∏ (—Ç–∏–ø–∞ "–ü–∞—É–∑–∞", "–í—Ö–æ–¥–∏—Ç") –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ–º –∫ —Ä–µ–ø–ª–∏–∫–µ
                        if self._is_short_stage_direction(next_line):
                            character_speech += f" [[{next_line}]]"
                            i += 1
                            continue
                        else:
                            # –î–ª–∏–Ω–Ω—ã–µ –∞–≤—Ç–æ—Ä—Å–∫–∏–µ —Ä–µ–º–∞—Ä–∫–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
                            break
                    
                    # –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–µ—á–∏ - –¥–æ–±–∞–≤–ª—è–µ–º
                    if self._is_speech_continuation(next_line):
                        character_speech += f" {next_line}"
                        i += 1
                        continue
                    
                    # –ò–Ω–∞—á–µ –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º
                    break
                
                normalized_lines.append(character_speech)
            else:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ä–µ–º–∞—Ä–∫–∏
                if self._is_stage_direction_line(line):
                    # –ê–≤—Ç–æ—Ä—Å–∫–∏–µ —Ä–µ–º–∞—Ä–∫–∏ –∑–∞–∫–ª—é—á–∞–µ–º –≤ [[]]
                    line = f"[[{line}]]"
                
                normalized_lines.append(line)
                i += 1
        
        return '\n'.join(normalized_lines)
    
    def _is_character_line(self, line: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Ä–µ–ø–ª–∏–∫–æ–π –ø–µ—Ä—Å–æ–Ω–∞–∂–∞"""
        import re
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ä–µ–ø–ª–∏–∫–∏ —Å –¥–≤–æ–µ—Ç–æ—á–∏–µ–º: "–ò–ú–Ø: —Ç–µ–∫—Å—Ç", "–ò–ú–Ø (–¥–µ–π—Å—Ç–≤–∏–µ): —Ç–µ–∫—Å—Ç", "–ò–ú–Ø [[–¥–µ–π—Å—Ç–≤–∏–µ]]: —Ç–µ–∫—Å—Ç"
        if re.match(r'^[–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]*(?:\([^)]+\)|\[\[[^\]]+\]\])?[–ê-–Ø–Å–∞-—è—ë\s]*:\s*.+', line):
            return True
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ä–µ–ø–ª–∏–∫–∏ —Å —Ç–æ—á–∫–æ–π (–∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç): "–ò–ú–Ø. —Ç–µ–∫—Å—Ç" –∏–ª–∏ "–ò–ú–Ø (–¥–µ–π—Å—Ç–≤–∏–µ). —Ç–µ–∫—Å—Ç"
        match = re.match(r'^([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]*(?:\([^)]+\))?)\s*\.\s*(.+)$', line)
        if match:
            speaker_part = match.group(1).strip()
            speech_part = match.group(2).strip()
            
            # –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —Ä–µ–º–∞—Ä–∫–æ–π —Å –¥–µ–π—Å—Ç–≤–∏—è–º–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            # –ù–û —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ –ù–ï –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Å–∫–æ–±–∫–∞—Ö –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Å–ª—É—á–∞–π: "–ò–º—è (–¥–µ–π—Å—Ç–≤–∏–µ –≤ —Å–∫–æ–±–∫–∞—Ö). –†–µ—á—å"
            # –≠—Ç–æ –¥–æ–ª–∂–Ω–æ –æ—Å—Ç–∞–≤–∞—Ç—å—Å—è —Ä–µ–ø–ª–∏–∫–æ–π –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            if re.match(r'^[–ê-–Ø–Å][–∞-—è—ë\s]*\s*\([^)]+\)\s*\.\s*.+', line):
                return True  # –≠—Ç–æ —Ä–µ–ø–ª–∏–∫–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ —Å —Ä–µ–º–∞—Ä–∫–æ–π –≤ —Å–∫–æ–±–∫–∞—Ö
            
            action_verbs = [
                '–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç', '–∏–≥—Ä–∞–µ—Ç', '–ø–æ–µ—Ç', '—Ç–∞–Ω—Ü—É–µ—Ç', '—Ö–æ–¥–∏—Ç', '–∏–¥–µ—Ç', '–±–µ–≥–∞–µ—Ç',
                '—Å–∞–¥–∏—Ç—Å—è', '–≤—Å—Ç–∞–µ—Ç', '–ª–æ–∂–∏—Ç—Å—è', '—É—Ö–æ–¥–∏—Ç', '–≤—Ö–æ–¥–∏—Ç', '–≤—ã—Ö–æ–¥–∏—Ç',
                '–±–µ—Ä–µ—Ç', '–¥–∞–µ—Ç', '–ø—å–µ—Ç', '–µ—Å—Ç', '—á–∏—Ç–∞–µ—Ç', '–ø–∏—à–µ—Ç', '—Å–º–æ—Ç—Ä–∏—Ç',
                '–∫—Ä–∏—á–∏—Ç', '—à–µ–ø—á–µ—Ç', '–ø–ª–∞—á–µ—Ç', '—Å–º–µ–µ—Ç—Å—è', '–º–æ–ª—á–∏—Ç', '–∫–ª–∏—á–µ—Ç'
            ]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –ª–∏ –≥–ª–∞–≥–æ–ª –¥–µ–π—Å—Ç–≤–∏—è –í–ù–ï —Å–∫–æ–±–æ–∫
            # –£–±–∏—Ä–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∫–æ–±–æ–∫ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç
            text_without_parentheses = re.sub(r'\([^)]*\)', '', line).lower()
            for verb in action_verbs:
                # –í–ê–ñ–ù–û: –ò—â–µ–º –ø–æ–ª–Ω—ã–µ —Å–ª–æ–≤–∞, –∞ –Ω–µ –ø–æ–¥—Å—Ç—Ä–æ–∫–∏ (–∏–∑–±–µ–≥–∞–µ–º "–¥–∞–µ—Ç" –≤ "–ø–æ–æ–±–µ–¥–∞–µ—Ç–µ")
                if re.search(r'\b' + verb + r'\b', text_without_parentheses):
                    return False  # –≠—Ç–æ —Ä–µ–º–∞—Ä–∫–∞, –∞ –Ω–µ —Ä–µ–ø–ª–∏–∫–∞
            
            # –ï—Å–ª–∏ —á–∞—Å—Ç—å —Å –≥–æ–≤–æ—Ä—è—â–∏–º —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –∏–ª–∏ —Å–∫–æ–±–∫–∏ - —ç—Ç–æ —Ä–µ–ø–ª–∏–∫–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            if (' ' in speaker_part or '(' in speaker_part or 
                len(speaker_part) > 4):  # –î–ª–∏–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ - —Ç–æ—á–Ω–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏
                return True
            
            # –ï—Å–ª–∏ —Ä–µ—á–µ–≤–∞—è —á–∞—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å–ª–æ–≤–æ —Å –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ–º - —ç—Ç–æ —Ä–µ–ø–ª–∏–∫–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            if not re.match(r'^[–ê-–Ø–Å][–∞-—è—ë]{0,2}\.\.\.?\s*$', speech_part):
                return True
            
        return False
    
    def _is_stage_direction_line(self, line: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Ä–µ–º–∞—Ä–∫–æ–π"""
        import re
        
        # –í–ê–ñ–ù–û: –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∏–º–µ–Ω–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞, —Ç–æ —ç—Ç–æ –ù–ï —Ä–µ–º–∞—Ä–∫–∞!
        if re.match(r'^[–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]*(?:\([^)]+\))?\s*[\.:]', line):
            return False
        
        # –¢–∏–ø–∏—á–Ω—ã–µ —Ä–µ–º–∞—Ä–∫–∏
        stage_direction_patterns = [
            r'^–ü–∞—É–∑–∞\.?$',
            r'^–ú–æ–ª—á–∞–Ω–∏–µ\.?$', 
            r'^–ó–∞–Ω–∞–≤–µ—Å\.?$',
            r'^–£—Ö–æ–¥–∏—Ç\.?$',
            r'^–í—Ö–æ–¥–∏—Ç\s+.+\.?$',
            r'^–í—ã—Ö–æ–¥–∏—Ç\s+.+\.?$',
            r'^\([^)]+\)\.?$',  # –†–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö
            r'^[–ê-–Ø–Å][–∞-—è—ë]+\s+(–∑–∞\s+—Å—Ü–µ–Ω–æ–π|–≤\s+–¥–≤–µ—Ä—è—Ö|–∏–∑-–∑–∞\s+–∫—É–ª–∏—Å)',  # –†–µ–º–∞—Ä–∫–∏ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –º–µ—Å—Ç–∞
            
            # –ê–≤—Ç–æ—Ä—Å–∫–∏–µ —Ä–µ–º–∞—Ä–∫–∏, –æ–ø–∏—Å—ã–≤–∞—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞ —Å—Ü–µ–Ω–µ
            r'^–°–ª—ã—à–Ω—ã?\s+(–≥–æ–ª–æ—Å–∞|–∑–≤—É–∫–∏|—à–∞–≥–∏)',  # "–°–ª—ã—à–Ω—ã –≥–æ–ª–æ—Å–∞", "–°–ª—ã—à–µ–Ω –∑–≤—É–∫"
            r'–∏–¥—É—Ç?\s+[–ê-–Ø–Å]',  # "–∏–¥—É—Ç –°–µ—Ä–µ–±—Ä—è–∫–æ–≤, –ï–ª–µ–Ω–∞ –ê–Ω–¥—Ä–µ–µ–≤–Ω–∞"
            r'–≤—Ö–æ–¥—è—Ç?\s+[–ê-–Ø–Å]',  # "–≤—Ö–æ–¥—è—Ç –ø–µ—Ä—Å–æ–Ω–∞–∂–∏"
            r'–≤—ã—Ö–æ–¥—è—Ç?\s+[–ê-–Ø–Å]',  # "–≤—ã—Ö–æ–¥—è—Ç –≤—Å–µ"
            r'–≤–æ–∑–≤—Ä–∞—â–∞—è—Å—å\s+—Å\s+–ø—Ä–æ–≥—É–ª–∫–∏',  # "–≤–æ–∑–≤—Ä–∞—â–∞—è—Å—å —Å –ø—Ä–æ–≥—É–ª–∫–∏"
            r'–∏–∑\s+–≥–ª—É–±–∏–Ω—ã\s+(—Å–∞–¥–∞|–ª–µ—Å–∞|–¥–æ–º–∞)',  # "–∏–∑ –≥–ª—É–±–∏–Ω—ã —Å–∞–¥–∞"
            
            # –î–µ–π—Å—Ç–≤–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ —Ä–µ–º–∞—Ä–∫–∞—Ö (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)
            r'^[–ê-–Ø–Å][–∞-—è—ë\s]{1,25}\s+(—É—Ö–æ–¥–∏—Ç|–≤—Ö–æ–¥–∏—Ç|–≤—ã—Ö–æ–¥–∏—Ç|—Å–∞–¥–∏—Ç—Å—è|–≤—Å—Ç–∞–µ—Ç|–ª–æ–∂–∏—Ç—Å—è)\b',  # "–ù—è–Ω—è —É—Ö–æ–¥–∏—Ç", "–ï–ª–µ–Ω–∞ –ê–Ω–¥—Ä–µ–µ–≤–Ω–∞ —É—Ö–æ–¥–∏—Ç"
            r'^[–ê-–Ø–Å][–∞-—è—ë\s]{1,25}\s+(–±–µ—Ä–µ—Ç|–¥–∞–µ—Ç|–ø—å–µ—Ç|–µ—Å—Ç|—á–∏—Ç–∞–µ—Ç|–ø–∏—à–µ—Ç|—Å–º–æ—Ç—Ä–∏—Ç)\b',    # "–ï–ª–µ–Ω–∞ –±–µ—Ä–µ—Ç", "–ï–ª–µ–Ω–∞ –ê–Ω–¥—Ä–µ–µ–≤–Ω–∞ –±–µ—Ä–µ—Ç"  
            r'(—É—Ö–æ–¥–∏—Ç|–≤—Ö–æ–¥–∏—Ç|–≤—ã—Ö–æ–¥–∏—Ç|–±–µ—Ä–µ—Ç|–¥–∞–µ—Ç|–ø—å–µ—Ç|—Å–∞–¥–∏—Ç—Å—è)\b.*,',  # –°–ª–æ–∂–Ω—ã–µ —Ä–µ–º–∞—Ä–∫–∏ —Å –∑–∞–ø—è—Ç—ã–º–∏
            r'—Å–∏–¥—è\s+(–Ω–∞|–≤|—É)\s+\w+',  # "—Å–∏–¥—è –Ω–∞ –∫–∞—á–µ–ª—è—Ö"
            r'—Å—Ç–æ—è\s+(—É|–≤–æ–∑–ª–µ|–æ–∫–æ–ª–æ)\s+\w+',  # "—Å—Ç–æ—è —É –æ–∫–Ω–∞"
            
            # –°–ª–æ–∂–Ω—ã–µ –º–Ω–æ–≥–æ—á–∞—Å—Ç–µ–≤—ã–µ —Ä–µ–º–∞—Ä–∫–∏
            r'^[–ê-–Ø–Å][–∞-—è—ë\s]{1,25}\s+(–∏–≥—Ä–∞–µ—Ç|–ø–æ–µ—Ç|–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç|–±—å–µ—Ç)\s+[–∞-—è—ë]+;',  # "–¢–µ–ª–µ–≥–∏–Ω –∏–≥—Ä–∞–µ—Ç –ø–æ–ª—å–∫—É;"
            r';.*–≤—Å–µ\s+(–º–æ–ª—á–∞|—Ç–∏—Ö–æ|–≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ)\s+(—Å–ª—É—à–∞—é—Ç|—Å–º–æ—Ç—Ä—è—Ç|–∂–¥—É—Ç)',  # "; –≤—Å–µ –º–æ–ª—á–∞ —Å–ª—É—à–∞—é—Ç"
            r';.*–≤—Ö–æ–¥–∏—Ç\s+[–∞-—è—ë]+',  # "; –≤—Ö–æ–¥–∏—Ç —Ä–∞–±–æ—Ç–Ω–∏–∫"
            r'^–û–±–∞\s+(—É—Ö–æ–¥—è—Ç|–∏–¥—É—Ç|–≤—Ö–æ–¥—è—Ç)',  # "–û–±–∞ —É—Ö–æ–¥—è—Ç –≤ –¥–æ–º"
            r'^–í—Å–µ\s+(–º–æ–ª—á–∞|—Ç–∏—Ö–æ|–≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ)\s+(—Å–ª—É—à–∞—é—Ç|—Å–º–æ—Ç—Ä—è—Ç)',  # "–í—Å–µ –º–æ–ª—á–∞ —Å–ª—É—à–∞—é—Ç"
            r'[–ê-–Ø–Å][–∞-—è—ë\s]{1,25}\s+(—Ö–æ–¥–∏—Ç|–∏–¥–µ—Ç|–±–µ–≥–∞–µ—Ç)\s+(–æ–∫–æ–ª–æ|–≤–æ–∑–ª–µ|–ø–æ)\s+',  # "–ú–∞—Ä–∏–Ω–∞ —Ö–æ–¥–∏—Ç –æ–∫–æ–ª–æ –¥–æ–º–∞"
            r'[–∞-—è—ë]+\s+(–∫—É—Ä|—Ü—ã–ø–ª—è—Ç|–∫–æ—Ç–∞|—Å–æ–±–∞–∫—É)',  # "–∫–ª–∏—á–µ—Ç –∫—É—Ä", "–∑–æ–≤–µ—Ç —Ü—ã–ø–ª—è—Ç"
            r'–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç\s+(–≥–∏—Ç–∞—Ä—É|–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç|—Å—Ç—Ä—É–Ω—ã)',  # "–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –≥–∏—Ç–∞—Ä—É"
            r'—á—Ç–æ-—Ç–æ\s+(–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç|–ø–∏—à–µ—Ç|—á–∏—Ç–∞–µ—Ç|–¥–µ–ª–∞–µ—Ç)',  # "—á—Ç–æ-—Ç–æ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç"
            r'\.\s*[–ê-–Ø–Å][–∞-—è—ë\s]{1,25}\s+(—Ö–æ–¥–∏—Ç|–∏–≥—Ä–∞–µ—Ç|–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç|–∫–ª–∏—á–µ—Ç)',  # ". –ú–∞—Ä–∏–Ω–∞ —Ö–æ–¥–∏—Ç –æ–∫–æ–ª–æ"
        ]
        
        for pattern in stage_direction_patterns:
            if re.search(pattern, line, re.IGNORECASE):
                return True
        
        return False
    
    def _is_short_stage_direction(self, line: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ä–µ–º–∞—Ä–∫–∞ –∫–æ—Ä–æ—Ç–∫–æ–π (–¥–ª—è –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∫ —Ä–µ–ø–ª–∏–∫–µ)
        –∏–ª–∏ –¥–ª–∏–Ω–Ω–æ–π –∞–≤—Ç–æ—Ä—Å–∫–æ–π (–¥–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–∏)
        """
        import re
        
        # –ö–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–º–∞—Ä–∫–∏ - –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ–º –∫ —Ä–µ–ø–ª–∏–∫–∞–º
        short_patterns = [
            r'^–ü–∞—É–∑–∞\.?$',
            r'^–ú–æ–ª—á–∞–Ω–∏–µ\.?$', 
            r'^–ó–∞–Ω–∞–≤–µ—Å\.?$',
            r'^–£—Ö–æ–¥–∏—Ç\.?$',
            r'^–í—Ö–æ–¥–∏—Ç\s+[–ê-–Ø–Å][–∞-—è—ë]+\.?$',  # –í—Ö–æ–¥–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–µ—Ä—Å–æ–Ω–∞–∂
            r'^–í—ã—Ö–æ–¥–∏—Ç\s+[–ê-–Ø–Å][–∞-—è—ë]+\.?$', # –í—ã—Ö–æ–¥–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–µ—Ä—Å–æ–Ω–∞–∂
            r'^\([^)]+\)\.?$',  # –†–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö
            r'^[–ê-–Ø–Å][–∞-—è—ë]+\s+(–∑–∞\s+—Å—Ü–µ–Ω–æ–π|–≤\s+–¥–≤–µ—Ä—è—Ö|–∏–∑-–∑–∞\s+–∫—É–ª–∏—Å)',
        ]
        
        for pattern in short_patterns:
            if re.match(pattern, line, re.IGNORECASE):
                return True
        
        # –ï—Å–ª–∏ –≤ —Å—Ç—Ä–æ–∫–µ –µ—Å—Ç—å –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é - —ç—Ç–æ –∞–≤—Ç–æ—Ä—Å–∫–∞—è —Ä–µ–º–∞—Ä–∫–∞
        if ',' in line and re.search(r'[–ê-–Ø–Å][–∞-—è—ë]+.*,.*[–ê-–Ø–Å][–∞-—è—ë]+', line):
            return False
            
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —Å–ª–æ–∂–Ω–∞—è –∞–≤—Ç–æ—Ä—Å–∫–∞—è —Ä–µ–º–∞—Ä–∫–∞
        if ';' in line:
            return False
            
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –¥–ª–∏–Ω–Ω–∞—è (–±–æ–ª–µ–µ 50 —Å–∏–º–≤–æ–ª–æ–≤) - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∞–≤—Ç–æ—Ä—Å–∫–∞—è —Ä–µ–º–∞—Ä–∫–∞
        if len(line) > 50:
            return False
            
        # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–º–∞—Ä–∫–∏ —Å—á–∏—Ç–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–º–∏
        return True
    
    def _is_speech_continuation(self, line: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º —Ä–µ—á–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞"""
        import re
        
        # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–µ—á–∏ - —Å—Ç—Ä–æ–∫–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ä–µ–º–∞—Ä–∫–æ–π
        if self._is_stage_direction_line(line):
            return False
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Å–ª—É—á–∞–π: –æ–¥–Ω–æ—Å–ª–æ–∂–Ω—ã–µ —Ñ—Ä–∞–∑—ã —Å –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ–º - —ç—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–µ—á–∏
        if re.match(r'^[–ê-–Ø–Å][–∞-—è—ë]{0,2}\.\.\.?\s*$', line):
            return True
            
        # –ï—Å–ª–∏ —ç—Ç–æ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–∞—è —Ä–µ–ø–ª–∏–∫–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ - –Ω–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
        if self._is_character_line(line):
            return False
            
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã, –Ω–æ —ç—Ç–æ –Ω–µ –∏–º—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
        # (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
        if re.match(r'^[–∞-—è—ë]', line):  # –°—Ç—Ä–æ—á–Ω–∞—è –±—É–∫–≤–∞ –≤ –Ω–∞—á–∞–ª–µ - —Ç–æ—á–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
            return True
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–Ω–∞–∫–æ–≤ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–µ—á–∏
        continuation_patterns = [
            r'^[–ê-–Ø–Å][–∞-—è—ë]+[,\.\!\?\s]',  # –û–±—ã—á–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
            r'^[–ê-–Ø–Å][–∞-—è—ë]*\s+[–∞-—è—ë]',   # –û–±—ã—á–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –ø—Ä–æ–±–µ–ª–æ–º
            r'^\.\.\.',  # –ú–Ω–æ–≥–æ—Ç–æ—á–∏–µ –≤ –Ω–∞—á–∞–ª–µ
            r'^‚Äî',       # –¢–∏—Ä–µ (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞)
        ]
        
        for pattern in continuation_patterns:
            if re.match(pattern, line):
                return True
                
        return False
    
    def _normalize_single_stage_direction(self, line: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—É—é —Ä–µ–º–∞—Ä–∫—É"""
        import re
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö
        if line.startswith('(') and line.endswith(')'):
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏ —Å–∫–æ–±–æ–∫
            inside = line[1:-1].strip()
            return f"({inside})"
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ä–µ–º–∞—Ä–∫–∏ (–ü–∞—É–∑–∞, –í—Ö–æ–¥–∏—Ç, etc.)
        elif re.match(r'(?i)^(–ø–∞—É–∑–∞|–≤—Ö–æ–¥–∏—Ç|–≤—ã—Ö–æ–¥–∏—Ç|—Å–∞–¥–∏—Ç—Å—è|–≤—Å—Ç–∞–µ—Ç|–º–æ–ª—á–∞–Ω–∏–µ)\.?$', line):
            return line.rstrip('.').title() + '.'
        
        return line

    def _final_cleanup(self, content: str) -> str:
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        import re
        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        content = re.sub(r'\n{3,}', '\n\n', content)
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
        lines = content.split('\n')
        lines = [line.rstrip() for line in lines]
        
        # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
        while lines and not lines[0]:
            lines.pop(0)
        while lines and not lines[-1]:
            lines.pop()
        
        return '\n'.join(lines)
    
    def _save_normalization_debug_files(self, raw_content: str, normalized_content: str, file_path: str):
        """–í—Ä–µ–º–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–æ –∏ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏"""
        import os
        from pathlib import Path
        from datetime import datetime
        
        print(f"================–°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª—ã –æ—Ç–ª–∞–¥–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è: {file_path}")
        # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∏ –ø—É—Ç–∏
        file_name = Path(file_path).stem
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤ —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
        logs_dir = Path(__file__).parent.parent.parent / "logs" / file_name
        logs_dir.mkdir(parents=True, exist_ok=True)
        
        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        raw_file = logs_dir / f"01_raw_content_{timestamp}.txt"
        with open(raw_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("–ò–°–•–û–î–ù–´–ô –ö–û–ù–¢–ï–ù–¢ (–î–û –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ò)\n")
            f.write("=" * 80 + "\n\n")
            f.write(raw_content)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        normalized_file = logs_dir / f"02_normalized_content_{timestamp}.txt"
        with open(normalized_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("–ù–û–†–ú–ê–õ–ò–ó–û–í–ê–ù–ù–´–ô –ö–û–ù–¢–ï–ù–¢ (–ü–û–°–õ–ï –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ò)\n")
            f.write("=" * 80 + "\n\n")
            f.write(normalized_content)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        comparison_file = logs_dir / f"03_comparison_{timestamp}.txt"
        with open(comparison_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("–°–†–ê–í–ù–ï–ù–ò–ï: –î–û –ò –ü–û–°–õ–ï –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ò\n")
            f.write("=" * 80 + "\n\n")
            
            f.write("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\n")
            f.write(f"   –ò—Å—Ö–æ–¥–Ω–∞—è –¥–ª–∏–Ω–∞: {len(raw_content)} —Å–∏–º–≤–æ–ª–æ–≤\n")
            f.write(f"   –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –¥–ª–∏–Ω–∞: {len(normalized_content)} —Å–∏–º–≤–æ–ª–æ–≤\n")
            f.write(f"   –†–∞–∑–Ω–∏—Ü–∞: {len(normalized_content) - len(raw_content)} —Å–∏–º–≤–æ–ª–æ–≤\n")
            raw_lines_count = len(raw_content.split('\n'))
            norm_lines_count = len(normalized_content.split('\n'))
            f.write(f"   –ò—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {raw_lines_count}\n")
            f.write(f"   –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {norm_lines_count}\n\n")
            
            f.write("üîç –ü–ï–†–í–´–ï 50 –°–¢–†–û–ö - –°–†–ê–í–ù–ï–ù–ò–ï:\n")
            f.write("-" * 80 + "\n")
            
            raw_lines = raw_content.split('\n')
            norm_lines = normalized_content.split('\n')
            
            max_lines = min(50, max(len(raw_lines), len(norm_lines)))
            
            for i in range(max_lines):
                f.write(f"–°—Ç—Ä–æ–∫–∞ {i+1:3d}:\n")
                
                if i < len(raw_lines):
                    f.write(f"  –î–û:    '{raw_lines[i]}'\n")
                else:
                    f.write(f"  –î–û:    [–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç]\n")
                
                if i < len(norm_lines):
                    f.write(f"  –ü–û–°–õ–ï: '{norm_lines[i]}'\n")
                else:
                    f.write(f"  –ü–û–°–õ–ï: [–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç]\n")
                
                f.write("\n")
        
        print(f"üóÇÔ∏è –§–∞–π–ª—ã –æ—Ç–ª–∞–¥–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {logs_dir}")
        print(f"   üìÑ –ò—Å—Ö–æ–¥–Ω—ã–π: {raw_file.name}")
        print(f"   üìÑ –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π: {normalized_file.name}")
        print(f"   üìÑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: {comparison_file.name}")
    
    def _cleanup_normalization_debug_files(self, file_path: str):
        """–í—Ä–µ–º–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤ –æ—Ç–ª–∞–¥–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏"""
        import shutil
        from pathlib import Path
        
        file_name = Path(file_path).stem
        logs_dir = Path(__file__).parent.parent.parent / "logs" / file_name
        
        if logs_dir.exists():
            # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (–Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å 01_, 02_, 03_)
            for file in logs_dir.glob("0[123]_*content*.txt"):
                file.unlink()
            for file in logs_dir.glob("03_comparison*.txt"):
                file.unlink()
            print(f"üßπ –§–∞–π–ª—ã –æ—Ç–ª–∞–¥–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —É–¥–∞–ª–µ–Ω—ã –∏–∑: {logs_dir}")
        else:
            print(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {logs_dir}")
    
    def _create_structured_content_from_text(self, raw_content: str, metadata: Dict[str, Any], 
                                           file_path: str) -> StructuredContent:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ —Å—ã—Ä–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
        –ë–∞–∑–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.
        """
        from .content_models import (
            ContentElement, DialogueElement, CharacterListElement,
            ContentType, StructuredContent
        )
        
        # –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ö–û–ù–¢–ï–ù–¢–ê –ü–ï–†–ï–î –ê–ù–ê–õ–ò–ó–û–ú
        normalized_content = self._normalize_play_content(raw_content)
        
        # –í–†–ï–ú–ï–ù–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª—ã –æ—Ç–ª–∞–¥–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        self._save_normalization_debug_files(raw_content, normalized_content, file_path)
        
        elements = []
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ù–û–†–ú–ê–õ–ò–ó–û–í–ê–ù–ù–´–ô —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –¥–∏–∞–ª–æ–≥–æ–≤
        dialogues = ContentAnalyzer.detect_dialogue_patterns(normalized_content)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ù–û–†–ú–ê–õ–ò–ó–û–í–ê–ù–ù–´–ô —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Å–ø–∏—Å–∫–æ–≤ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        character_lists = ContentAnalyzer.detect_character_lists(normalized_content)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–∏—Å–∫–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        for char_list in character_lists:
            start_pos = self._get_text_position_by_line(normalized_content, char_list['start_line'])
            end_pos = self._get_text_position_by_line(normalized_content, char_list['end_line'])
            
            element = CharacterListElement(
                type=ContentType.CHARACTER_LIST,
                content=char_list['section_title'],
                position=start_pos,
                length=end_pos - start_pos,
                characters=char_list['characters']
            )
            elements.append(element)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∏–∞–ª–æ–≥–∏
        processed_lines = set()
        for dialogue in dialogues:
            line_pos = self._get_text_position_by_line(normalized_content, dialogue['line_number'])
            
            element = DialogueElement(
                type=ContentType.DIALOGUE,
                content=dialogue['text'],
                position=line_pos,
                length=len(dialogue['original_line']),
                speaker=dialogue['speaker']
            )
            elements.append(element)
            processed_lines.add(dialogue['line_number'])
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç –∫–∞–∫ –Ω–∞—Ä—Ä–∞—Ç–∏–≤–Ω—ã–π
        lines = normalized_content.split('\n')
        for i, line in enumerate(lines):
            if i not in processed_lines and line.strip():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≤—Ö–æ–¥–∏—Ç –ª–∏ —ç—Ç–∞ —Å—Ç—Ä–æ–∫–∞ –≤ —Å–ø–∏—Å–æ–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
                in_character_list = any(
                    char_list['start_line'] <= i <= char_list['end_line']
                    for char_list in character_lists
                )
                
                if not in_character_list:
                    line_pos = self._get_text_position_by_line(normalized_content, i)
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                    content_type = self._detect_content_type(line.strip())
                    
                    element = ContentElement(
                        type=content_type,
                        content=line.strip(),
                        position=line_pos,
                        length=len(line)
                    )
                    elements.append(element)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ –ø–æ–∑–∏—Ü–∏–∏
        elements.sort(key=lambda x: x.position)
        
        return StructuredContent(
            elements=elements,
            raw_content=normalized_content,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
            metadata=metadata,
            source_file=file_path
        )
    
    def _get_text_position_by_line(self, text: str, line_number: int) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–∑–∏—Ü–∏—é —Å–∏–º–≤–æ–ª–∞ –ø–æ –Ω–æ–º–µ—Ä—É —Å—Ç—Ä–æ–∫–∏"""
        lines = text.split('\n')
        position = 0
        
        for i in range(min(line_number, len(lines))):
            if i > 0:
                position += 1  # –£—á–∏—Ç—ã–≤–∞–µ–º —Å–∏–º–≤–æ–ª –ø–µ—Ä–µ–≤–æ–¥–∞ —Å—Ç—Ä–æ–∫–∏
            position += len(lines[i])
        
        return position
    
    def _detect_content_type(self, line: str):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Å—Ç—Ä–æ–∫–∏"""
        import re
        from .content_models import ContentType
        
        line_lower = line.lower()
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π/–∞–∫—Ç–æ–≤
        if re.search(r'\b(–¥–µ–π—Å—Ç–≤–∏–µ|–∞–∫—Ç|–∫–∞—Ä—Ç–∏–Ω–∞|—Å—Ü–µ–Ω–∞|—è–≤–ª–µ–Ω–∏–µ|–ø—Ä–æ–ª–æ–≥|—ç–ø–∏–ª–æ–≥)\b', line_lower):
            return ContentType.CHAPTER_TITLE
        
        # –°—Ü–µ–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–º–∞—Ä–∫–∏ (–≤ —Å–∫–æ–±–∫–∞—Ö –∏–ª–∏ –∫—É—Ä—Å–∏–≤–µ)
        if (line.startswith('(') and line.endswith(')')) or \
           (line.startswith('[') and line.endswith(']')):
            return ContentType.STAGE_DIRECTION
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –Ω–∞—Ä—Ä–∞—Ç–∏–≤
        return ContentType.NARRATIVE
