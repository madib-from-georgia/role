"""
Rule-based –ø–∞—Ä—Å–µ—Ä –ø—å–µ—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏ –¥–∏–∞–ª–æ–≥–æ–≤
–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ —Å–æ—Å–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –Ω–∞—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
"""

import re
from typing import List, Tuple, Optional
from loguru import logger

from ..models import CharacterData, SpeechData, SpeechType


class PlayParser:
    """
    Rule-based –ø–∞—Ä—Å–µ—Ä –ø—å–µ—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏ –¥–∏–∞–ª–æ–≥–æ–≤
    
    –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
    - ‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: < 0.1—Å
    - üéØ –¢–æ—á–Ω–æ—Å—Ç—å: 100% –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—å–µ—Å
    - üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: 0 —Ä—É–±–ª–µ–π
    - üìù –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: –≤–æ–∑—Ä–∞—Å—Ç, –ø—Ä–æ—Ñ–µ—Å—Å–∏—è, —Ä–æ–¥—Å—Ç–≤–æ
    """
    
    def __init__(self):
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–µ–∫—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        self.character_section_patterns = [
            r"(?i)–¥–µ–π—Å—Ç–≤—É—é—â–∏–µ\s+–ª–∏—Ü–∞[:\s]*\n",
            r"(?i)–î–ï–ô–°–¢–í–£–Æ–©–ò–ï\s+–õ–ò–¶–ê[:\s]*\n",
            r"(?i)–¥–µ–π—Å—Ç–≤—É—é—â–∏–µ\s+–ª–∏—Ü–∞[:\s]*$",
            r"(?i)–î–ï–ô–°–¢–í–£–Æ–©–ò–ï\s+–õ–ò–¶–ê[:\s]*$",
            r"(?i)–ª–∏—Ü–∞[:\s]*\n",
            r"(?i)–õ–ò–¶–ê[:\s]*\n",
            r"(?i)–ª–∏—Ü–∞[:\s]*$",
            r"(?i)–õ–ò–¶–ê[:\s]*$",
            r"(?i)–ø–µ—Ä—Å–æ–Ω–∞–∂–∏[:\s]*\n",
            r"(?i)–ü–ï–†–°–û–ù–ê–ñ–ò[:\s]*\n",
            r"(?i)–ø–µ—Ä—Å–æ–Ω–∞–∂–∏[:\s]*$",
            r"(?i)–ü–ï–†–°–û–ù–ê–ñ–ò[:\s]*$"
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–Ω—Ü–∞ —Å–µ–∫—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        self.section_end_patterns = [
            r"(?i)–¥–µ–π—Å—Ç–≤–∏–µ\s+\w+",
            r"(?i)–ê–ö–¢\s+[IVX]+",
            r"(?i)–ö–ê–†–¢–ò–ù–ê\s+\w+",
            r"(?i)–ø—Ä–æ–ª–æ–≥",
            r"(?i)–ü–†–û–õ–û–ì",
            r"(?i)—Å—Ü–µ–Ω–∞\s+\w+",
            r"(?i)–°–¶–ï–ù–ê\s+\w+",
            r"(?i)—è–≤–ª–µ–Ω–∏–µ\s+\w+",
            r"(?i)–Ø–í–õ–ï–ù–ò–ï\s+\w+"
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
        self.character_line_patterns = [
            # –§–æ—Ä–º–∞—Ç: "–ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ –§–∞–º–∏–ª–∏—è (–ü—Ä–æ–∑–≤–∏—â–µ), –æ–ø–∏—Å–∞–Ω–∏–µ."
            r"^([–ê-–Ø–Å–∞-—è—ë][–ê-–Ø–Å–∞-—è—ë\s]+(?:\([–ê-–Ø–Å–∞-—è—ë\s]+\))?),\s*(.+)$",
            # –§–æ—Ä–º–∞—Ç: "–ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ –§–∞–º–∏–ª–∏—è, –æ–ø–∏—Å–∞–Ω–∏–µ."
            r"^([–ê-–Ø–Å–∞-—è—ë][–ê-–Ø–Å–∞-—è—ë\s]+?),\s*(.+)$",
            # –§–æ—Ä–º–∞—Ç: "–ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ –§–∞–º–∏–ª–∏—è ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ"
            r"^([–ê-–Ø–Å–∞-—è—ë][–ê-–Ø–Å–∞-—è—ë\s]+?)\s*[‚Äî‚Äì-]\s*(.+)$",
            # –§–æ—Ä–º–∞—Ç: "–ò–º—è –æ–ø–∏—Å–∞–Ω–∏–µ" (–±–µ–∑ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è)
            r"^([–ê-–Ø–Å–∞-—è—ë][–ê-–Ø–Å–∞-—è—ë\s]+?)\s+([–∞-—è—ë].+)$",
            # –§–æ—Ä–º–∞—Ç: —Ç–æ–ª—å–∫–æ –∏–º—è –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è
            r"^([–ê-–Ø–Å–∞-—è—ë][–ê-–Ø–Å–∞-—è—ë\s]+?)\.?\s*$"
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å—Ç—Ä–æ–∫
        self.service_line_patterns = [
            r"(?i)^–≤\s+–¥–æ–º–µ\s+",
            r"(?i)^–¥–µ–π—Å—Ç–≤–∏–µ\s+",
            r"(?i)^–∞–∫—Ç\s+",
            r"(?i)^–∫–∞—Ä—Ç–∏–Ω–∞\s+",
            r"(?i)^—Å—Ü–µ–Ω–∞\s+",
            r"(?i)^—è–≤–ª–µ–Ω–∏–µ\s+",
            r"(?i)^–ø—Ä–æ–ª–æ–≥\s*$",
            r"(?i)^—ç–ø–∏–ª–æ–≥\s*$",
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å–µ–∫—Ü–∏–π –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
            r"(?i)^–¥–µ–π—Å—Ç–≤—É—é—â–∏–µ\s+–ª–∏—Ü–∞\s*$",
            r"(?i)^–ª–∏—Ü–∞\s*$",
            r"(?i)^–ø–µ—Ä—Å–æ–Ω–∞–∂–∏\s*$",
            r"(?i)^–¥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∏–µ\s+–ª–∏—Ü–∞\s*$",
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∫
            r"(?i)^–¥–µ–π—Å—Ç–≤–∏–µ\s+–ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç\s+",
            r"(?i)^–≤—Ä–µ–º—è\s+–¥–µ–π—Å—Ç–≤–∏—è\s+",
            r"(?i)^–º–µ—Å—Ç–æ\s+–¥–µ–π—Å—Ç–≤–∏—è\s+"
        ]
    
    def extract_characters(self, text: str) -> List[CharacterData]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø—å–µ—Å—ã
        
        Args:
            text: –¢–µ–∫—Å—Ç –ø—å–µ—Å—ã
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        """
        logger.debug(f"–ù–∞—á–∏–Ω–∞—é –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª–∏–Ω–æ–π {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        characters = []
        
        # –ü–æ–∏—Å–∫ —Å–µ–∫—Ü–∏–∏ —Å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º–∏
        character_section = self._find_character_section(text)
        if character_section:
            logger.debug("–ù–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è —Å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥")
            characters = self._parse_character_section(character_section)
            
            # –ï—Å–ª–∏ –≤ —Å–µ–∫—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –ø—Ä–æ–±—É–µ–º –¥–∏–∞–ª–æ–≥–∏
            if not characters:
                logger.debug("–í —Å–µ–∫—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤")
                characters = self._extract_characters_from_dialogues(text)
        else:
            logger.debug("–°–µ–∫—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤")
            characters = self._extract_characters_from_dialogues(text)
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã (–ø–æ –∏–º–µ–Ω–∏)
        characters = self._deduplicate_characters(characters)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏ –≤–∞–∂–Ω–æ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
        self._calculate_character_metrics(characters, text)
        
        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(characters)} –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π")
        return characters
    
    def extract_speech_attributions(self, text: str, characters: List[CharacterData]) -> List[SpeechData]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ü–∏–π —Ä–µ—á–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –ø—å–µ—Å—ã
            characters: –°–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∞—Ç—Ä–∏–±—É—Ü–∏–π —Ä–µ—á–∏
        """
        logger.debug("–ù–∞—á–∏–Ω–∞—é –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ü–∏–π —Ä–µ—á–∏")
        
        speech_attributions = []
        character_names = set()
        
        # –°–æ–∑–¥–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∏–º–µ–Ω –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        for char in characters:
            character_names.add(char.name)
            character_names.update(char.aliases)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤ (—Å —É—á–µ—Ç–æ–º –æ—Ç—Å—Ç—É–ø–æ–≤ –∏ –¥–µ–π—Å—Ç–≤–∏–π –≤ —Å–∫–æ–±–∫–∞—Ö –∏–ª–∏ [[]])
        dialogue_pattern = r'^\s*([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s]*(?:\([^)]+\)|\[\[[^\]]+\]\])?[–ê-–Ø–Å–∞-—è—ë\s]*?):\s*(.+)$'
        
        lines = text.split('\n')
        position = 0
        
        for line in lines:
            line_stripped = line.strip()
            if not line_stripped:
                position += len(line) + 1
                continue
                
            match = re.match(dialogue_pattern, line)
            if match:
                speaker_name = match.group(1).strip()
                speech_text = match.group(2).strip()
                
                # –£–±–∏—Ä–∞–µ–º –¥–µ–π—Å—Ç–≤–∏—è –≤ —Å–∫–æ–±–∫–∞—Ö –∏ [[]] –∏–∑ –∏–º–µ–Ω–∏ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º–∏
                speaker_name_clean = re.sub(r'\s*\([^)]+\)\s*', '', speaker_name)
                speaker_name_clean = re.sub(r'\s*\[\[[^\]]+\]\]\s*', '', speaker_name_clean).strip()
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º—è –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
                speaker_name_clean = re.sub(r'\s+', ' ', speaker_name_clean)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–∞–∫–æ–π –ø–µ—Ä—Å–æ–Ω–∞–∂ –≤ –Ω–∞—à–µ–º —Å–ø–∏—Å–∫–µ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—á–∏—â–µ–Ω–Ω–æ–µ –∏–º—è)
                character_found = None
                for char in characters:
                    if (char.name == speaker_name_clean or
                        speaker_name_clean in char.aliases or
                        self._names_similar(char.name, speaker_name_clean)):
                        character_found = char
                        break
                
                if character_found:
                    speech_data = SpeechData(
                        character_name=character_found.name,
                        text=speech_text,
                        position=position,
                        speech_type=SpeechType.DIALOGUE,
                        confidence=1.0,
                        context=None
                    )
                    speech_attributions.append(speech_data)
            
            position += len(line) + 1
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(speech_attributions)} –∞—Ç—Ä–∏–±—É—Ü–∏–π —Ä–µ—á–∏")
        return speech_attributions
    
    def is_play_format(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –ø—å–µ—Å–æ–π
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            True, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –∏–º–µ–µ—Ç —Ñ–æ—Ä–º–∞—Ç –ø—å–µ—Å—ã
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–µ–∫—Ü–∏–∏ "–î–µ–π—Å—Ç–≤—É—é—â–∏–µ –ª–∏—Ü–∞"
        for pattern in self.character_section_patterns:
            if re.search(pattern, text, re.MULTILINE):
                logger.debug("–ù–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è '–î–µ–π—Å—Ç–≤—É—é—â–∏–µ –ª–∏—Ü–∞'")
                return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "–ò–ú–Ø: —Ç–µ–∫—Å—Ç" (—Å —É—á–µ—Ç–æ–º –æ—Ç—Å—Ç—É–ø–æ–≤)
        dialogue_pattern = r'^\s*[–ê-–Ø–Å][–ê-–Ø–Å\s]+:\s*.+$'
        dialogue_matches = re.findall(dialogue_pattern, text, re.MULTILINE)
        
        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ 2 –∏–ª–∏ –±–æ–ª—å—à–µ –¥–∏–∞–ª–æ–≥–æ–≤, —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –ø—å–µ—Å–æ–π
        if len(dialogue_matches) >= 2:
            logger.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(dialogue_matches)} –¥–∏–∞–ª–æ–≥–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –ø—å–µ—Å—ã")
            return True
        
        logger.debug("–¢–µ–∫—Å—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω –∫–∞–∫ –ø—å–µ—Å–∞")
        return False
    
    def _find_character_section(self, text: str) -> Optional[str]:
        """–ü–æ–∏—Å–∫ —Å–µ–∫—Ü–∏–∏ —Å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º–∏ –≤ —Ç–µ–∫—Å—Ç–µ"""
        # –ò—â–µ–º –Ω–∞—á–∞–ª–æ —Å–µ–∫—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        start_match = None
        start_pos = -1
        
        for pattern in self.character_section_patterns:
            match = re.search(pattern, text, re.MULTILINE)
            if match:
                start_match = match
                start_pos = match.end()
                break
        
        if not start_match:
            return None
        
        # –ò—â–µ–º –∫–æ–Ω–µ—Ü —Å–µ–∫—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        end_pos = len(text)
        text_after_start = text[start_pos:]
        
        for pattern in self.section_end_patterns:
            match = re.search(pattern, text_after_start, re.MULTILINE)
            if match:
                end_pos = start_pos + match.start()
                break
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–µ–∫—Ü–∏—é –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        character_section = text[start_pos:end_pos].strip()
        logger.debug(f"–ù–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –¥–ª–∏–Ω–æ–π {len(character_section)} —Å–∏–º–≤–æ–ª–æ–≤")
        return character_section
    
    def _parse_character_section(self, section: str) -> List[CharacterData]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å–µ–∫—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π"""
        characters = []
        lines = section.split('\n')
        
        for i, line in enumerate(lines):
            line = line.strip()
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            if not line or len(line) < 3:
                continue
            
            # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫—É –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            character = self._parse_character_line(line, i + 1)
            if character:
                characters.append(character)
        
        logger.debug(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(characters)} –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏–∑ —Å–µ–∫—Ü–∏–∏")
        return characters
    
    def _parse_character_line(self, line: str, index: int) -> Optional[CharacterData]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫–∏ —Å –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–º"""
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–æ–±–µ–ª—ã
        line = re.sub(r'^\s*[-‚Äî‚Äì‚Ä¢]\s*', '', line)
        line = line.strip()
        
        if not line:
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–ª—É–∂–µ–±–Ω–æ–π
        for service_pattern in self.service_line_patterns:
            if re.match(service_pattern, line):
                return None
        
        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–¥–µ–ª–∏—Ç—å –∏–º—è –∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é —Ä–∞–∑–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        name = None
        description = None
        
        for pattern in self.character_line_patterns:
            match = re.match(pattern, line)
            if match:
                name = match.group(1).strip()
                description = match.group(2).strip() if len(match.groups()) > 1 and match.group(2) else None
                break
        
        # –ï—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏
        if not name:
            name_match = re.match(r'^([–ê-–Ø–Å–∞-—è—ë][–ê-–Ø–Å–∞-—è—ë\s]+?)(?:[,‚Äî‚Äì-]|$)', line)
            if name_match:
                name = name_match.group(1).strip()
                remaining = line[len(name):].strip()
                if remaining and remaining.startswith((',', '‚Äî', '‚Äì', '-')):
                    description = remaining[1:].strip()
        
        if name:
            # –û—á–∏—â–∞–µ–º –∏–º—è –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            name = re.sub(r'[,\.\-‚Äî‚Äì]+$', '', name).strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–º—è –Ω–µ –ø—É—Å—Ç–æ–µ –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –±—É–∫–≤—ã
            if name and re.search(r'[–ê-–Ø–Å–∞-—è—ë]', name) and len(name.split()) <= 5:
                return CharacterData(
                    name=name,
                    aliases=[],
                    description=description,
                    mentions_count=0,
                    first_mention_position=0,
                    importance_score=0.0,
                    source="character_list"
                )
        
        return None
    
    def _extract_characters_from_dialogues(self, text: str) -> List[CharacterData]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ '–ò–ú–Ø: —Ç–µ–∫—Å—Ç'"""
        characters = []
        character_names = set()
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤ (—Å —É—á–µ—Ç–æ–º –æ—Ç—Å—Ç—É–ø–æ–≤)
        dialogue_pattern = r'^\s*([–ê-–Ø–Å][–ê-–Ø–Å\s]+):\s*.+$'
        
        for i, line in enumerate(text.split('\n')):
            match = re.match(dialogue_pattern, line)
            if match:
                name = match.group(1).strip()
                
                # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
                name = re.sub(r'\s+', ' ', name)
                
                if name and name not in character_names:
                    character_names.add(name)
                    
                    character = CharacterData(
                        name=name,
                        aliases=[],
                        description=None,
                        mentions_count=0,
                        first_mention_position=0,
                        importance_score=0.0,
                        source="dialogue_extraction"
                    )
                    characters.append(character)
        
        logger.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(characters)} –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤")
        return characters
    
    def _calculate_character_metrics(self, characters: List[CharacterData], text: str) -> None:
        """–ü–æ–¥—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π (—É–ø–æ–º–∏–Ω–∞–Ω–∏—è, –≤–∞–∂–Ω–æ—Å—Ç—å)"""
        text_lower = text.lower()
        text_length = len(text)
        
        for character in characters:
            name_lower = character.name.lower()
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
            mentions = 0
            first_mention = -1
            
            # –ò—â–µ–º –ø–æ–ª–Ω–æ–µ –∏–º—è
            full_name_mentions = len(re.findall(re.escape(name_lower), text_lower))
            mentions += full_name_mentions
            
            # –ò—â–µ–º –ø–µ—Ä–≤–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ
            first_match = text_lower.find(name_lower)
            if first_match != -1:
                first_mention = first_match
            
            # –ò—â–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∏–º–µ–Ω–∏ (–µ—Å–ª–∏ –∏–º—è —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–æ–≤)
            name_parts = name_lower.split()
            if len(name_parts) > 1:
                for part in name_parts:
                    if len(part) > 2:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ —Ç–∏–ø–∞ "–¥–µ", "—Ñ–æ–Ω"
                        part_mentions = len(re.findall(r'\b' + re.escape(part) + r'\b', text_lower))
                        mentions += part_mentions
                        
                        part_match = text_lower.find(part)
                        if part_match != -1 and (first_mention == -1 or part_match < first_mention):
                            first_mention = part_match
            
            character.mentions_count = mentions
            character.first_mention_position = max(0, first_mention)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
            if mentions > 0:
                # –ë–∞–∑–æ–≤–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
                mention_score = min(mentions / 10.0, 1.0)  # –ú–∞–∫—Å–∏–º—É–º –ø—Ä–∏ 10+ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è—Ö
                
                # –ë–æ–Ω—É—Å –∑–∞ —Ä–∞–Ω–Ω–µ–µ –ø–æ—è–≤–ª–µ–Ω–∏–µ
                early_bonus = 1.0 - (first_mention / text_length) if first_mention >= 0 else 0.0
                early_bonus *= 0.2  # –ú–∞–∫—Å–∏–º—É–º 20% –±–æ–Ω—É—Å–∞
                
                # –ë–æ–Ω—É—Å –∑–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ (–ø–µ—Ä—Å–æ–Ω–∞–∂–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ –≤–∞–∂–Ω–µ–µ)
                source_bonus = 0.1 if character.source == "character_list" else 0.0
                
                character.importance_score = min(mention_score + early_bonus + source_bonus, 1.0)
            else:
                character.importance_score = 0.1 if character.source == "character_list" else 0.0
    
    def _names_similar(self, name1: str, name2: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏–º–µ–Ω (–¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤–∞—Ä–∏–∞—Ü–∏–π)"""
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –æ–¥–Ω–æ –∏–º—è –≤—Ö–æ–¥–∏—Ç –≤ –¥—Ä—É–≥–æ–µ
        name1_lower = name1.lower()
        name2_lower = name2.lower()
        
        name1_words = set(name1_lower.split())
        name2_words = set(name2_lower.split())
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ–±—â–∏–µ —Å–ª–æ–≤–∞ –¥–ª–∏–Ω–Ω–µ–µ 2 —Å–∏–º–≤–æ–ª–æ–≤
        common_words = name1_words.intersection(name2_words)
        return any(len(word) > 2 for word in common_words)
    
    def _deduplicate_characters(self, characters: List[CharacterData]) -> List[CharacterData]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –ø–æ –∏–º–µ–Ω–∏"""
        seen_names = set()
        unique_characters = []
        
        for character in characters:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            normalized_name = re.sub(r'\s+', ' ', character.name.strip())
            
            if normalized_name not in seen_names:
                seen_names.add(normalized_name)
                unique_characters.append(character)
            else:
                logger.debug(f"–£–¥–∞–ª–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç –ø–µ—Ä—Å–æ–Ω–∞–∂–∞: {character.name}")
        
        logger.debug(f"–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(characters)} -> {len(unique_characters)} –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π")
        return unique_characters
    
    def get_extraction_stats(self, text: str, characters: List[CharacterData]) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è"""
        return {
            "method_used": "rule_based_play_parser",
            "is_play_format": self.is_play_format(text),
            "has_character_section": self._find_character_section(text) is not None,
            "total_characters": len(characters),
            "text_length": len(text),
            "characters_from_list": len([c for c in characters if c.source == "character_list"]),
            "characters_from_dialogues": len([c for c in characters if c.source == "dialogue_extraction"])
        }
